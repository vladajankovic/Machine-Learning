## Homework - IS
- Linear Regression (Gradient Descent) and KNN models on simple datasets

## Homework - PSZ
- Book price prediction from an online book store
  - Web scraping using Scrapy framework
  - Data analysis and visualization
  - Data and feature engineering
  - Linear Regression with Gradient Descent implementation from scratch
  - Logistic Regressions (One-vs-One and Multinomial) implementation from scratch
  - Lightweight GUI for testing Regression models
  - K-Means Clustering implementation from scratch and 3D visualization

## Homework - SIBP
- Kaggle competition [Regression with a Mohs Hardness Dataset](https://www.kaggle.com/competitions/playground-series-s3e25)
  - Feature engineering
  - Comparing performances of various Regression models with Hyperparameter tuning
  - Regression models used:
    - Linear Regression
    - Rigde Regression
    - LASSO Regression
    - Elastic Net Regression
    - SGD Regression (Stohastic Gradient Descent)
  - Decision tree models and Ensemble models used:
    - Decision Tree Regression
    - Random Forest Regression
    - Gradient Boosting Regression
    - Histogram-based Gradient Boosting Regression
    - Voting Regression
    - XGB Regression (Extreme Gradient Boosting)
  - Nearest Neighbor models used:
    - KNN Regression (K-Neareset Neighbors)
  - Neural network models used:
    - MPL Regression (Multi-layer Perceptron)
